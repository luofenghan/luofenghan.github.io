{"meta":{"title":"唯有日月不灭","subtitle":null,"description":null,"author":"落枫寒","url":"http://www.vibrancy.cn"},"pages":[{"title":"关于","date":"2017-01-16T15:24:04.000Z","updated":"2017-01-16T15:24:29.826Z","comments":true,"path":"about/index.html","permalink":"http://www.vibrancy.cn/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2017-01-16T15:21:44.000Z","updated":"2017-01-16T15:22:19.052Z","comments":true,"path":"categories/index.html","permalink":"http://www.vibrancy.cn/categories/index.html","excerpt":"","text":""},{"title":"文章","date":"2017-01-16T15:31:12.000Z","updated":"2017-04-29T02:19:33.383Z","comments":true,"path":"archives/index.html","permalink":"http://www.vibrancy.cn/archives/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-01-16T15:22:46.000Z","updated":"2017-01-16T15:23:17.675Z","comments":true,"path":"tags/index.html","permalink":"http://www.vibrancy.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM知识自查表——Java内存区域","slug":"jvm-knowledge-self-java-memory-area","date":"2017-06-17T09:36:44.000Z","updated":"2017-06-17T10:00:47.763Z","comments":true,"path":"repository/jvm-knowledge-self-java-memory-area.html","link":"","permalink":"http://www.vibrancy.cn/repository/jvm-knowledge-self-java-memory-area.html","excerpt":"","text":"运行时数据区有哪些运行时数据区主要分为所有线程共享的数据区和线程隔离的数据区。线程共享的数据区主要包括方法区和Java堆；线程隔离的数据区主要包括虚拟机栈、程序计数器和本地方法栈。什么是程序计数器以及他的用途程序计数器是一块较小的内存空间，它的用于当前线程执行字节码的信号指示器。字节码指示器通过改变这个计数器的值来选取下一个需要执行的字节码指令。由于Java虚拟机的多线程是通过线程轮流切换并分配CPU执行时间来的方式来实现的，在一个时间片内，一个处理器只会执行一个线程指令。因此，为了在线程切换后能够恢复到正确的执行位置，每个线程都需要独立的程序计数器，互补影响，独立存储（这也是为什么程序计数器数据区是线程隔离的原因）。什么是虚拟机栈Java的虚拟机栈也是线程私有的，它的生命周期与线程相同。它描述的是Java方法执行的内存模型：每个方法执行的时候都会创建一个栈帧，每个方法从调用到执行完成的过程，就对应一个栈帧在虚拟机栈里面从入栈到出栈的过程。Java虚拟机规范对虚拟机栈定义了两种异常情况StackOverflowError：如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出该异常。OutOfMemoryError：一般虚拟机可以动态扩展，如果扩展后也无法申请到足够内存时将抛出该异常。什么是栈帧栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区虚拟机栈的栈元素。栈帧中存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。一个线程的方法调用链可能很长，很多方法都同时处于执行状态。对于执行引擎来讲，在活动线程中，只有栈顶的栈帧是有效的，称为“当前栈帧”，当前栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。在编译程序代码时，栈帧中需要多大的局部变量表、多深的操作数栈都已经完全确定，因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于虚拟机的具体实现。什么是局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。局部变量表所需要的空间大小会在程序编译期就完全确定下来，在方法的Code属性的max_locals数据项中存储了该方法所以需要分配的最大局部变量表的容量。局部变量表的容量以变量槽为最小单位，一般一个slot的长度为32位。对于64位的数据类型，虚拟机会以高位在前的方式为其分配两个连续的slot空间。由于局部变量表是建立在线程堆栈上，是线程私有的数据，无论读写两个连续的slot是否是原子操作，都不会引起数据安全问题。如何访问局部变量表虚拟机通过索引定位的方式。因为变量在局部变量表中都是按照顺序来排列的，当参数表分配完毕后，再根据方法内部定义的局部变量顺序和作用域分配其余slot。如果是实例方法，那么在局部变量表中第0位索引的slot默认是方法所属对象的this引用。讲讲局部变量表的slot可重用特性在方法体中定义的变量，其作用域并不一定会覆盖整个方法体，如果当前字节码的PC计数器的值已经超出了某个变量的作用域，那么这个变量对应的slot可以交由其他变量使用。如果执行GC时，变量还在作用域之内，那么无论如何都不会回收的；1234567891011121314public static void main(String[] args) &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; System.gc();&#125;垃圾收集结果： PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 66141K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 75% used [0x0000000081c00000,0x0000000085c97450,0x0000000087180000) Metaspace used 3175K, capacity 4494K, committed 4864K, reserved 1056768K class space used 346K, capacity 386K, committed 512K, reserved 1048576K如果执行GC时，在变量的作用域之外，从代码逻辑上讲，placeholder已经不可能再被访问，但实际结果来看，这64MB的内存并没有被回收。12345678910111213141516public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; System.gc();&#125;垃圾收集结果： PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 66141K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 75% used [0x0000000081c00000,0x0000000085c97450,0x0000000087180000) Metaspace used 3175K, capacity 4494K, committed 4864K, reserved 1056768K class space used 346K, capacity 386K, committed 512K, reserved 1048576K在变量的作用域之外，初始化另一个局部变量，此时执行GC，将会回收内存。1234567891011121314151617public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; int a=0; System.gc();&#125;运行结果: PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 605K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 0% used [0x0000000081c00000,0x0000000081c97440,0x0000000087180000) Metaspace used 3175K, capacity 4494K, committed 4864K, reserved 1056768K class space used 346K, capacity 386K, committed 512K, reserved 1048576K在第一次修改后，代码虽然已经离开了placeholder的作用域，但在此之后，没有任何对局部变量表的读写操作，placeholder原本所占用的Slot还没有被其他变量所复用，所以作为GC Roots一部分的局部变量表仍然保存着对他的关联。什么是操作数栈当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的。在方法执行的过程中，会有各种字节码指令向操作数栈中写入和提取内容，也就是入栈和出栈操作。操作数栈的最大深度也是在编译期就确定下来，记录到Code属性的max_stacks数据项中。操作数栈的每一个元素可以是任意的Java数据类型。另外，操作数栈的元素类型必须与字节码的指令序列要求的类型严格匹配。什么是动态连接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。什么是方法返回地址当一个方法被执行后，有两种方式退出这个方法。执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为正常完成出口。当方法执行遇到了异常，并且这个异常没有在方法体内得到处理，没有在本方法内的异常表中搜索到匹配的异常处理器，就会导致方法退出，这种退出的方式称为异常完成出口。当方法正常退出时，调用者的PC计数器的值就可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器表决定，栈帧中一般不会保存这部分消息。方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用者指令后面的一条指令。什么是Java堆Java堆是Java虚拟机所管理的内存中最大的一块，也是被所有线程共享的一块区域，在虚拟机启动时创建。此内存存在的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆也是垃圾收集器管理的主要区域，因此很多时候也被称作“GC堆”（Garbage Collected Heap），Java堆会划分成很多区域从内存回收的角度来看由于现在收集器基本采用的是分代收集算法，所以Java堆还可以细分为新生代和老年代，新生代还分有Eden、FromSurvivor和ToSurvivor空间。从内存分配的角度来看，线程共享的Java堆会划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。无论如何划分区域，都与存储内容无关，无论哪个区域，存储的都是对象实例，进一步划分是为了更好的回收内存，或者更快的分配内存。另外，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现时，既可以实现固定大小的，也可以是扩展的。不过主流虚拟机都是按照可扩展来实现的（通过\\(-Xmx\\)和\\(-Xms\\)来控制）。如果在堆中没有内存完成实例分配，并且堆也无法在扩展时，将会抛出OutOfMemeoryError异常。什么是方法区方法区和Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Java虚拟机规范对这个区域的管理非常宽松，除了不需要连续的内存和可以选择固定大小或可扩展外，还可以选择不实现垃圾收集。不实现垃圾收集，并非数据进入方法区就如“永久代”的名字一样永久存在了，对这个区域的==内存回收目标==主要是针对常量池的回收和对类型的卸载。运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中也有常量池（Constant Pool），Class文件中的常量池用于存放编译器生成的各种字面量、符号引用和翻译出来的直接引用，这部分内容将在==类加载后==存放到方法区的运行时常量池中。运行时常量池的相对于Class文件常量池的另一个重要特征就是具备动态性，在运行期间也能将新的常量放入池中，例如调用String类的\\(intern()\\)方法。当常量池无法申请到内存时会抛出\\(OutOfMemeoryError\\)异常。什么是直接内存在JDK1.4中新加入的NIO类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的\\(DirectByteBuffer\\)对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，避免在Java堆和Native堆中来回复制数据。这部分内存也会导致\\(OutOfMemoryError\\)异常出现，虽然不会受到Java堆大小的限制，但是，既然是内存，则肯定会受到本机总内存的大小和处理器寻址空间的限制。如何去访问对象对象访问在Java语言中无处不在，即使是最简单的访问，也会涉及Java栈、Java堆、方法区这三个最重要内存区域之间的关联关系。例如如下代码：Object obj = new Object();Object obj：这部分语义会反映到虚拟机栈的局部变量表中，作为一个reference类型数据存在。new Object()：这部分语义会反映到Java堆中，形成一块存储了Object类型所有实例数据值（对象中各个实例字段的数据）的结构化内存。另外，在Java堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据存储到方法区中。Java虚拟机规范规定了虚拟机栈的局部变量表中的reference类型为一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及通过哪种方式去访问到Java堆中的对象的具体位置。不同的虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄访问方式Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。使用句柄访问的优点：reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中实例数据指针，而reference本身不许要被改变。使用直接指针访问方式Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，reference中直接存储的就是对象的地址。使用直接指针访问方式的优点：速度更快，节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这种开销积少成多也是一项非常可观的成本。内存分配参数解释参数名用途-Xms设置初始堆内存-Xmx设置最大可用内存，如果最大可用内存和初始内存相同，可以避免每次垃圾回收后重新分配内存-Xss设置每个线程的堆栈容量大小，理论上减少这个值能生成更多的线程-Xoss设置本地方法栈的大小-XX:PermSize设置方法区初始内存大小-XX:MaxPermSize设置方法区最大内存大小-XX:MaxDirectMemorySize=10M设置最大直接内存大小如何实现Java堆溢出Java堆用于存储对象实例，只要不断地创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，就会在对象数量到达最大堆的容量限制后产生内存溢出异常。1234567891011/** * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError */public class HeapOOM &#123; public static void main(String[] args) &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Object()); &#125; &#125;&#125;1234567891011121314151617运行结果：java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid12160.hprof ...Exception in thread &quot;main&quot; Heap dump file created [28125483 bytes in 0.211 secs]java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at com.cwc.test.jvm.test.HeapOOM.main(HeapOOM.java:14) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)如何实现虚拟机栈和本地方法栈溢出在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说，\\(-Xoss\\)参数虽然存在，但实际上是无效的，栈容量只由\\(-Xss\\)参数设定。如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出\\(StackOverflowError\\)异常。12345678910111213141516171819202122/** * VM Args: -Xss128k */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak() &#123; this.stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF sof = new JavaVMStackSOF(); try &#123; sof.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println(\"stack length:\" + sof.stackLength); throw e; &#125; &#125;&#125;123456789101112131415 运行结果： stack length:978 Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.cwc.test.jvm.test.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at com.cwc.test.jvm.test.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at com.cwc.test.jvm.test.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at com.cwc.test.jvm.test.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.cwc.test.jvm.test.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)··· at com.cwc.test.jvm.test.JavaVMStackSOF.main(JavaVMStackSOF.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)结果表明：在单个线程下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是\\(StackOverflowError\\)异常。如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出\\(OutOfMemoryError\\)异常。1234567891011121314151617181920212223242526/** * VM Args: -Xss2M */public class JavaVMStackOOM &#123; private void doNotStop() &#123; while (true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while (true) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; doNotStop(); &#125; &#125;); thread.start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125;在多线程环境下，给每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。因为，操作系统分配给每个进程的内存是有限制的，虚拟机提供参数来控制Java堆和方法区的这两部分内存的最大值。假如剩余内存有2GB，减去Xmx（最大堆容量），再减去MaxPermSize（最大方法区容量），程序计数器消耗内存小，可以忽略。如果虚拟机进程本身耗费的内存在计算在内，剩下的内存就由虚拟机栈和本地方法栈“瓜分”了。++每个线程分配到的栈容量越大，可以建立的线程数量自然就越少++，建立线程时就越容易把剩下的内存耗尽。因此，如果是建立多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。如何实现运行时常量池溢出如果要向运行时常量池添加内容，最简单的方法就是使用\\(String.intern()\\)这个Native方法。由于运行时常量池分配在方法区内，我们可以通过\\(-XX:permSize\\)和\\(-XX:MaxPermSize\\)限制方法区的大小，从而间接限制其中的常量池容量。123456789101112131415/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; String s = \"abc\"; while (true) &#123; s += s; list.add(s.intern()); &#125; &#125;&#125;1234运行结果：Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method) at org.fenixsoft.oom.RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:18)从运行结果可看出，运行时常量池溢出，在\\(OutOfMemoryError\\)后面的提示信息“PermGen Space”，说明运行时常量池处于方法区。怎样实现方法区溢出方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。对于这个区域的测试，基本思路是运行时产生大量的类去填满方法区，直到溢出。123456789101112131415161718/** * VM Args: -XX:MetaspaceSize=10M -XX:MaxMetaspaceSize=10M */public class JavaMethodAreaOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) -&gt; methodProxy.invokeSuper(o, args)); enhancer.create(); &#125; &#125;&#125;方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾回收器回收掉，判定条件非常苛刻。在经常动态生成大量Class的应用中，需要特别注意类的回收状况。在大量JSP或动态产生JSP文件的应用（JSP第一次运行会被编译为Java类）、基于OSGI的应用（即使是同一个类文件，被不同的加载器加载也会视为不同的类）。怎样实现本机直接内存溢出DirectMemory容量可以通过\\(-XX:MaxDirectMemorySize\\)指定，如果不指定，则默认与Java堆的最大值(-Xmx指定)一样。123456789101112131415161718/** * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M */public class DirectMemoryOOM &#123; private static final int _1MB = 1024; public static void main(String[] args) throws IllegalAccessException &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true)&#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125;","categories":[{"name":"jvm","slug":"jvm","permalink":"http://www.vibrancy.cn/categories/jvm/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.vibrancy.cn/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://www.vibrancy.cn/tags/jvm/"},{"name":"运行时数据区","slug":"运行时数据区","permalink":"http://www.vibrancy.cn/tags/运行时数据区/"}]},{"title":"多线程知识自查表——并发基础理论","slug":"multi-thread-knowledge-self-concurrent-basic-theory","date":"2017-06-13T08:44:55.000Z","updated":"2017-06-13T11:25:32.605Z","comments":true,"path":"repository/multi-thread-knowledge-self-concurrent-basic-theory.html","link":"","permalink":"http://www.vibrancy.cn/repository/multi-thread-knowledge-self-concurrent-basic-theory.html","excerpt":"","text":"什么是对象的状态对象的状态是指存储在实例或静态域中的数据。如果对象中所有的域都是基本类型的变量，那么这些域将构成对象的全部状态；如果对象中的域引用了其他的对象，那么该对象的状态将包含被引用对象的域。例如，LinkedList对象的状态包括该链表中所有节点对象的状态。一个对象是否线程安全的，取决于它是否被多个线程访问。当有多个线程访问某个状态变量并且其中有一个线程执行写入操作时，那么必须采用同步机制来协同这些线程对变量的访问。对象的哪些域不属于对象状态的一部分如果以某个对象为根节点构造一张对象图，那么该对象状态将是对象图中的所有对象包含的域的一个子集。也就是说，在定义哪些变量将构成对象的状态时，只考虑对象拥有的数据。所有权意味着控制权，然而，如果发布了某个可变对象的引用，那么就不再拥有独占的控制权，最多是“共享控制权”。对于从构造函数中传递进来的对象，类通常并不拥有这些对象。容器类通常表现出一种“所有权分离”的形式，其中容器类拥有自身的状态，客户代码则拥有容器中各个对象的状态。什么是线程安全性当多个线程访问某个类时，这个类始终都能表现出正确的行为，那么就称这个类是线程安全的。无状态对象一定是线程安全的。因为它既不包含任何域，又不包含任何对其他类中的域的引用。方法中的临时变量一定是线程安全的，因为计算过程中的临时状态仅存在于线程栈上的局部变量表中，并且只能由正在执行的线程访问。线程安全核心是什么线程安全核心在于要对状态访问操作进行管理，其中的状态主要包括以下两种状态：共享的（Shared）：变量可以由多个线程同时访问；可变的（Mutable）：变量的值在其生命周期内可以发生变化。什么是原子性例如，在一个计数器程序中，定义一个int类型的实例变量用于统计某个方法的访问次数，该方法每调用一次，就执行i++操作，但该操作并不是线程安全的。因为看上去i++是一个非常紧凑的语法，但是该操作并不是原子的。实际上，它包括了三个独立的操作：读取i的值，将值+1，然后将计算结果写入i。也就是说，这是一个读取——修改——写入的操作序列，其结果状态依赖于之前的状态。所以，一个操作的原子性是指该操作是不可分割的，其他线程只能在修改操作完成之前或之后读取和修改状态，而不能在修改状态的过程中。什么是竞态条件在并发编程中，当某个计算取决于多线程的交替执行时序时，那么就会发生竞态条件（Race Condition）。多数情况下，竞态条件不一定会发生错误，还需要某种不恰当的执行时序。竞态条件的常见情况延迟初始化基于对象之前的状态来定义对象状态的转换解决竞态条件的方法就是需要包含一组以原子方式执行的操作。可以使用java.util.concurrent.atomic包中的一些原子变量类，用于实现在数值和对象引用上的原子状态转换。或者使用锁将保护的代码路径以串行方式来访问，使复合操作成为原子操作。Java提供了哪些同步机制主要的同步机制是关键字synchronized，它提供了一种独占的加锁方式。另外，还包括volatile类型的变量，显式锁以及原子变量。什么是synchronizedJava提供了一种内置锁来支持原子性：同步代码块。同步代码块包括两个部分，一个作为锁的对象引用，一个作为这个锁保护的代码块。以synchronized来修饰的方法就是一种横跨整个方法体的同步代码块，其中该同步代码块的锁就是方法调用所在的对象，静态的synchronized方法以Class对象作为锁。Java内置锁相当于一种互斥体，意味着最多只有一个线程能够持有这种锁，其他线程必须等待或阻塞，直到持有这个锁的线程释放锁。如果某个线程视图已经获得某个对象的锁，那么持有锁的过程中，也可以访问该对象的其他synchronized来修饰的方法，这个称作锁的可重入。重入意味着获取锁的操作的粒度是线程，而不是调用。假设没有可重入的锁，那么就会发生死锁。因此，重入避免了这种死锁的发生。另外，仅仅将复合操作封装到一个同步代码块中是不够的。如果用同步来协调多线程对某个变量的访问，那么在访问这个变量的所有位置都需要使用同步，而且该同步锁必须是同一把锁。如果不加区别的将每个方法都加上锁，这可能会导致活跃性问题或性能问题。如果该加锁的方法是一个耗时操作，那么其他所有的线程都必须等待。当执行时间较长的计算或者可能无法快速完成的操作时，一定不要持有锁。因此，可以缩小同步代码块的范围，做到既保证并发性，同时又维护线程安全性。不过，要确保同步代码块不要太小，并且不要将本应是原子的操作拆分到多个同步代码块中。尽量将不影响共享状态且执行时间较长的操作从同步代码块中分离出去。什么是volatile关键字用途volatile修饰的变量可用来确保该变量的更新操作会通知到其他线程。访问volatile变量的时候不会执行加锁操作，也就不会线程阻塞。因此，volatile变量是一种比sychronized关键字更轻量级的同步机制。从内存可见性的角度来看，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。应用场景volatile变量通常用作于某个操作完成、发生中断或者状态的标志。使用条件对变量的写入操作不依赖当前的值（避免出现竞态条件），或者能够确保只有单个线程更新变量的值；该变量不会与其他状态变量一起纳入不变性条件中；在访问变量时不需要加锁。与Synchronized的区别加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。因为volatile的语义不足以确保递增操作的原子性，除非能够保证只有一个线程对变量执行写操作。什么是对象的发布发布（Publish）一个对象是指使对象能够在当前作用域之外的代码中使用。例如，将一个指向对象的引用保存到其他代码可以访问的地方；或者将引用传递到其他类的方法中。什么是对象的逃逸逃逸是指当发布一个对象时，在该对象的非私有域中引用的所有对象同样会被发布。某个对象逃逸之后，必须假设有某个类或线程可能会误用该对象。另一种特殊的逃逸是指this引用逃逸，是指对象还没有构造完成，它的this引用就会被发布出去。这会危及到线程安全，因为其他线程可以通过这个逸出的引用访问到初始化了一半的对象。其结果就是，某些线程看到该对象的状态是没初始化完的状态，而另外一些线程看到的却是已经初始化完的状态，这种不一致性是不确定的，程序也会产生一些无法预知的并发错误。this引用逃逸逃逸发生要满足两个条件:在构造函数中创建内部类；在构造函数中就把这个内部类给发布出去了。因此，要防止this引用逸出的方法就是避免让这两个条件同时出现。什么是线程封闭当访问共享的可变数据时，通常需要使用同步。一种避免使用同步的方式就是不共享数据。将某个对象封闭在线程中，将会自动实现线程安全性，即使被封闭的对象本身不是线程安全的，这种技术被称为线程封闭。线程封闭技术的一个常见应用是JDBC的Connection对象。JDBC规范并不要求Connection对象是安全的。在典型的服务器应用程序中，线程从连接池获得一个Connection对象，并且用该对象来处理请求，使用完对象后再将对象返还给连接池。由于大多数请求都是由单个线程采用同步的方式来处理，并且在Connection对象返回之前，连接池不会再将它分配给其他线程。因此，这种连接管理模式在处理请求时隐含地将Connection对象封闭在线程中。线程封闭有哪些实现栈封闭在栈封闭中，只能通过局部变量才能访问对象，局部变量的特性就是封闭在执行线程中，他们位于执行线程的栈中，其他线程无法访问这个栈。另外，在维持对象引用的栈封闭性时，需要保证被引用的对象不会逸出。ThreadLocalThreadLocal类能够使线程的某个值与保存该值的线程对象关联起来。ThreadLocal提供了get和set等方法，这些方法使每个使用该变量的线程都存有一个独立的副本，因此get总是返回由当前执行线程在调用set设置的最新值。当某个线程初次调用ThreadLocal.get方法时，就会调用initialValue来获取初始值。这些特定于线程的值保存在Thread对象中，当线程终止后，这些值会作为垃圾回收。12345678public class ConnectionPool&#123; private static ThreadLocal&lt;Connection&gt; connectionHolder = ThreadLocal.withInitial(() -&gt; DriverManager.getConnecton(DB_URL)); public static Connection getConnection()&#123; return connectionHolder.get(); &#125;&#125;如果此时需要将一个单线程应用程序移植到多线程环境中，通过将共享的全局变量转换为ThreadLocal对象，可以维持线程安全性，从而避免了对可变的单实例变量或全局变量进行共享。当某个频繁执行的操作需要一个临时对象，例如一个缓冲区，而同时又希望在每次执行时都重新分配该临时对象，就可以使用该技术。什么是不可变性首先不可变对象一定是线程安全的。其次，不可变对象需要满足以下条件：对象创建后其状态不能被修改；对象的所有域都是final类型；对象是正确创建的（对象创建期间，this引用没有逸出）。final的特点用于构造不可变对象，final类型的域是不能被修改的。它会保证不受限制的访问不可变对象，并在共享这些对象是无需同步。在编程中，除非需要某个域是可变的，否则应该将其声明为final域；当访问和更新多个相关变量时出现竞争条件问题时，可以通过将这些变量全部封装在一个不可变对象中来消除竞争。如果是一个可变对象，那么就必须使用锁来确保原子性。如果是一个不可变对象，那么当线程获得了对该对象的引用后，就不必担心另一个线程会修改对象的状态。123456789101112131415161718192021222324252627282930public class VolatileCachedFactorizer &#123; private volatile OneValueCache cache = new OneValueCache(null, null); public BigInteger[] service(BigInteger num) &#123; BigInteger[] lastFactors = cache.getFactors(num); if (lastFactors == null) &#123; lastFactors = factor(num); cache = new OneValueCache(num, lastFactors); &#125; return lastFactors; &#125; class OneValueCache &#123; private final BigInteger lastNumber; private final BigInteger[] lastFactors; public OneValueCache(BigInteger lastNumber, BigInteger[] lastFactors) &#123; this.lastNumber = lastNumber; this.lastFactors = Arrays.copyOf(lastFactors, lastFactors.length); &#125; public BigInteger[] getFactors(BigInteger i) &#123; if (lastNumber == null || !lastNumber.equals(i)) &#123; return null; &#125; else &#123; return Arrays.copyOf(lastFactors, lastFactors.length); &#125; &#125; &#125;&#125;如何去安全发布一个对象对象的发布需求取决于它的可变性不可变对象可以通过任意机制来发布；事实不可变的对象必须通过安全方式发布；可变对象必须通过安全方式发布，并且必须是线程安全的或者由某个锁保护起来。要安全发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式来安全的发布：在静态初始化函数中初始化一个对象引用；将对象的引用保存到volatile类型的域或者AtomicReference对象中；将对象的引用保存到某个正确构造对象的final类型域中；将对象的引用保存到一个由锁保护的域中。在并发程序中使用和共享对象时，可以使用一些使用的策略线程封闭：线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由该线程修改；只读共享：在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象线程安全共享：线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。保护对象：被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。什么是不变性条件和后验条件，以及他们的用途不变性条件用于判断状态是有效还是无效的，不变式表达了对状态的约束，这些状态应该符合这个约束的值的组合。后验条件用来判断状态迁移是否有效，规定了调用方法后必须为真的条件。用途类的不变性条件和后验条件约束了对象上有哪些状态和状态转换是有效的。如果不了解对象的不变性条件和后验条件，那么就不能确保线程安全性。要满足在状态变量的有效值或状态转换上的各种约束条件，就需要借助于原子性和封装性。什么是同步策略同步策略（Synchronization Policy）定义了如何在不违背对象不变性条件或后验条件的情况下，对状态的访问操作进行协同。同时，同步策略还规定了如何将不可变性、线程封闭与加锁机制等结合起来以维护线程的安全性，并且还规定了哪些变量由哪些锁来保护。什么是依赖状态的操作在某些对象的方法中包含了一些基于状态的先验条件。例如，不能从空队列中删除一个元素，在删除一个元素之前，必须保证队列处于非空状态。因此，如果某个操作包含基于状态的先验条件，那么这个操作就称为依赖状态的操作。在单线程程序中，如果某个操作无法满足先验条件，那么就只能失败。但在并发程序中，先验条件可能会由其他线程的执行而变为真，在并发程序中要一直等到先验条件成立在执行该操作。要想实现某个等待先验条件为真时才执行的操作，一种更为简单的方法就是通过现有类库（阻塞队列[BlockingQueue]）或者信号量来实现依赖状态的行为。如何设计线程安全的类在设计线程安全的类中，需要包含以下三个基本要素：找出构成对象状态的所有变量；找出约束对象状态的不变性条件；建立对象状态的并发访问管理策略。委托是创建线程安全类的一个最有效的策略，只需让现有的线程安全类管理所有的状态即可。如何以线程安全的方式访问非线程安全对象可以使用实例封闭机制（Instance Confinement），当对象被封闭到另一个对象中时，能够访问被封装对象的所有代码路径都是已知的。通过将封闭机制与合适的加锁策略结合起来，可以确保以线程安全的方式来使用非线程安全的对象。实例封闭是构建线程安全的一个最简单的方式，简化了线程安全类的实现过程。还使得在锁策略上的选择拥有了更多的灵活性，使得不同的状态变量可以由不同的锁策略来保护。Java平台类库中，由很多实例封闭的示例，有些类的唯一用途就是将非线程安全的类转换为线程安全的类。例如，包装器工厂方法（Collections.synchronizedList及同族的方法），使得这些非线程安全的类可以安全地用于多线程环境。这些工厂方法利用装饰器模式，使用一个同步的包装器对象包装容器；包装器将相关接口的每个方法实现为同步方法，并将请求转发到下层的容器对象上。只要包装器对象占有着对下层容器唯一的可触及的引用（底层容器限制于包装器内），包装器对象就是线程安全的。使用私有的锁对象而不是内置锁的好处123456789public class PrivateLock &#123; private final Object lock = new Object(); void doSomething() &#123; synchronized (lock) &#123; //修改变量的状态 &#125; &#125;&#125;私有的锁可以将被封装起来，使客户端代码无法得到锁；但客户端代码可以通过公有方法来访问锁，以便正确的参与到它的同步策略中。实现更加细粒度的加锁策略来提高可伸缩性。如果类中的各个组件已经是线程安全的，是否需要再增加一个额外的安全层？如果一个类是由多个独立且线程安全的状态变量组成，并且在所有的操作中都不包含无效状态转换，那么可以将线程安全性委托给底层的状态变量，不需要在封装类中再增加一个额外的安全层。类似于volatile变量的规则：仅当一个变量参与到包含其他状态变量的不变性条件时，才可以声明为volatile类型。例如，在NumberRange使用了两个AtomicInteger来管理状态，并且含有一个约束条件，即第一个数值要小于第二个数值。12345678910111213141516171819202122public class NumberRange &#123; private final AtomicInteger lower = new AtomicInteger(); private final AtomicInteger upper = new AtomicInteger(); public void setLower(int i) &#123; if (i &gt; upper.get()) &#123; throw new IllegalArgumentException(); &#125; lower.set(i); &#125; public void setUpper(int i) &#123; if (i &lt; lower.get()) &#123; throw new IllegalArgumentException(); &#125; upper.set(i); &#125; public boolean isInRange(int i) &#123; return (i &gt;= lower.get() &amp;&amp; i &lt;= upper.get()); &#125;&#125;然而，NumberRange并不是线程安全的，如果一个线程调用setLower(5)，另一个线程调用setUpper(4)，那么在一些错误的执行时序中，这两个调用将会通过检查，并都能执行成功，但结果状态是一个无效的状态。因为没有维持对下界和上界进行约束的不变性条件。setLower和setUpper都是“先检查后执行”的操作，但他们没有使用足够的加锁机制来保证这些操作的原子性。虽然AtomicInteger是线程安全的，但经过组合得到的类却不是，由于状态变量lower和upper不是彼此独立的，因此NumberRange不能将线程安全性委托给它的线程安全状态变量。因此，NumberRange必须通过加锁机制来维护不变性条件以确保线程安全性，此外，还必须避免发布lower和upper，从而防止客户端代码破坏其不变性条件。当把线程安全性委托给某个对象的底层状态变量时，在什么条件下才可以发布这些变量从而使其他类能够修改他们呢？如果一个状态变量是线程安全的，并且没有任何不变性条件来约束它的值，在变量的操作上也不存在任何不允许的状态转换，那么就可以安全的发布这个变量。线程安全且可变的Point类1234567891011121314151617public class SafePoint &#123; public int x, y; public SafePoint(int x, int y) &#123; this.x = x; this.y = y; &#125; public synchronized void set(int x, int y) &#123; this.x = x; this.y = y; &#125; public synchronized int[] get() &#123; return new int[]&#123;x, y&#125;; &#125;&#125;安全发布底层状态的车辆追踪器1234567891011121314151617181920212223public class PublishingVehicleTracker &#123; private final ConcurrentHashMap&lt;String, SafePoint&gt; locations; private final Map&lt;String, SafePoint&gt; unmodifiableMap; public PublishingVehicleTracker(ConcurrentHashMap&lt;String, SafePoint&gt; locations) &#123; this.locations = new ConcurrentHashMap&lt;&gt;(locations); this.unmodifiableMap = Collections.unmodifiableMap(locations); &#125; public Map&lt;String, SafePoint&gt; getLocations() &#123; return unmodifiableMap; &#125; public SafePoint getLocation(String id) &#123; return locations.get(id); &#125; public void setLocation(String id, int x, int y) &#123; if (locations.replace(id, new SafePoint(x, y)) == null) &#123; throw new IllegalArgumentException(); &#125; &#125;&#125;谈谈对ConcurrentHashMap的了解ConcurrentHashMap也是一个基于散列的Map，但他使用了一个完全不同的加锁策略来提供更高的并发性和伸缩性。ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只能有一个线程访问容器，而是使用一种粒度更细的加锁机制来实现更大程度的共享，这种机制称为分段锁（Lock Striping）。在这种机制中，任意数量的读取线程可以并发的访问Map，执行读取操作的线程和执行写入操作的线程可以并发地访问Map。ConcurrentHashMap带来的结果就是，在并发访问环境下将实现更高的吞吐量，而在单线程环境中只损失非常小的性能。ConcurrentHashMap提供的迭代器不会抛出ConcurrentModificationException，因此不需要在迭代过程中对容器加锁。ConcurrentHashMap返回的迭代器具有弱一致性，而并非及时失败。弱一致性可以容忍并发的修改，当创建迭代器时会遍历已有的元素，并可以在迭代器被构造后将修改操作反映给容器。ConcurrentHashMap尽管有这些改进，但仍有一些需要权衡的因素，对于一些需要在整个Map上进行计算的方法，例如size和isEmpty，这些方法的语义被略微减弱以反映整个容器的并发性。由于size返回的结果在计算时可能已经过期，但他实际上只是一个估计值，因此允许size返回一个近似值而不是一个精确值。但是，事实上size和isEmpty这样的方法在并发过程中的用处很小，因为他们的返回值总是不断变化。因此，这些操作的需求被弱化，以换取对其他更重要操作的性能优化。ConcurrentHashMap不能被加锁来执行独占的访问，因此无法在客户端加锁来创建新的原子操作。一些常见的复合操作，例如若没有则添加、若相等则移除、若相等则替换，都已实现为原子操作并且在ConcurrentMap接口中声明。如果你需要在现有的同步Map中添加这样的功能，那么就是用ConcurrentMap接口。12345678910public interface ConcurrentMap&lt;K,V&gt; extends Map&lt;K,V&gt;&#123; V putIfAbsent(K key, V value); boolean remove(K key, V value); boolean replace(K key, V oldValue, V newValue); V replace(K key, V newValue);&#125;谈谈对CopyOnWriteArrayList的了解基本原理CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。不过在CopyOnWriteArrayList中add方法的实现（向CopyOnWriteArrayList里添加元素），可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。应用场景CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。实现代码如下：使用注意减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。CopyOnWrite的缺点内存占用问题：有可能造成频繁的Yong GC和Full GC数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。基于阻塞队列生产者和消费者模式什么是生产者——消费者模式生产者——消费者模式将“找出需要完成的工作”与“执行工作”这两个过程分离开来，并把工作项放入一个“待完成”列表中以便在随后处理，而不是找出后立即处理。生产者和消费者模式简化了开发过程，因为它消除了生产者类和消费者类之间的代码依赖性，此外，该模式还将生产数据的过程和使用数据的过程解耦开来以简化工作负载的管理。什么是阻塞队列阻塞队列提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。如果队列已经满了，那么put方法将阻塞直到有空间可用；如果队列为空，那么take方法将会阻塞直到有元素可用。阻塞队列在生产者——消费者模式的运用如果生产者生成工作的速率比消费者处理工作的速率快，那么工作项会在队列中累计起来，并最终消耗内存。同样，put方法的阻塞特性极大的简化了生产者的编码。如果使用有界队列，那么当队列充满时，生产者将阻塞并且不能继续生成工作，而消费者就有时间赶上工作处理进度。因此，有界队列是一种强大的资源管理工具：能够抑制并防止产生过多的工作项，使应用程序在负荷过载的情况下变得更加健壮。阻塞队列同样提供一个offer方法，如果数据项不能被添加到队列中，那么将返回一个失败状态。这样你就能够创建更多灵活性的策略来处理负荷过载的情况。例如减轻负重，将多余的工作项序列化并写入磁盘，减少生产者线程数量，或通过某种方式抑制生产者线程。阻塞队列的具体实现以及应用在类库中包含了BlockingQueue的多种实现，其中LinkedBlockingQueue和ArrayBlockingQueue是FIFO队列，二者分别于LinkedList和ArrayList类似，但比同步List拥有更好的并发性。PriorityBlockingQueue是一个按优先级排序的队列，如果希望按照某种顺序而不是FIFO来处理元素时，该队列非常有用。SynchronousQueue不会为队列中的元素维护存储空间，它会维护一组线程。当任务到达的时候，会直接交付工作给某一个线程去执行，从而降低了将数据从生产者移动到消费者的延迟。这就好比，将文件直接交给同事，还是将文件放到他的邮箱并希望他能尽快拿到文件。SynchronousQueue没有存储功能，因此put和take会一直阻塞，直到有另一个线程已经准备参与到交付过程中。仅当有足够的消费者，并且总是有一个消费者准备好获取交付的工作时，才适合使用同步队列。什么是双端队列和工作密取Deque是一个双端队列，实现了在队列头和队列尾的高效插入和移除。具体实现包括ArrayDeque和LinkedBlockingDeque。在生产者——消费者设计中，所有消费者有一个共享的工作队列，而在工作密取设计中，每个消费者都有各自的双端队列。如果一个消费者完成了自己双端队列中的全部工作，那么它可以从其他消费者各自的双端队列末尾秘密地获取工作。密取工作模式比传统的生产者——消费者模式具有更高的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。大多数时候，只在访问自己的双端队列，从而极大的减少了竞争。工作密取非常适用于既是消费者也是生产者的问题——当执行某个工作可能导致更多的工作。例如，在网页爬虫程序处理一个页面时，通常会发现有更多的页面需要处理。当一个工作线程找到新的任务单元时，它将会放到自己队列的末尾。当双端队列为空时，它会在另一个线程的队列队尾查找新的任务，从而确保每个线程都保持忙碌状态。同步工具类用途同步工具类可以是任何一个对象，只要它可以根据其自身的状态来协调线程的控制流。阻塞队列可以作为同步工具类，其他类型的同步工具还包括信号量（Semaphore）、栅栏（Barrier）以及闭锁（Latch）。所有的同步工具类都有一些特定的结构化属性：封装了一些状态，这些状态将决定执行同步工具类的线程是继续执行还是等待。闭锁什么是闭锁闭锁是一种同步工具类，可以延迟线程的工作进度直到其到达终止状态。闭锁的作用相当于一扇门：在闭锁达到结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当达到结束状态时，这扇门会打开并允许所有线程通过。当闭锁达到结束状态之后，将不会再改变状态，因此这扇门将永远保持打开状态。总而言之，闭锁可以用来确保某些活动直到其他活动都完成后才继续执行。CountDownLatchCountDownLatch是一种灵活的闭锁实现，它可以使一个或多个线程等待一组事件发生。闭锁状态包括一个计数器，该计数器被初始化为一个正数，表示需要等待的事件数量。countDown递减计数器，表示有一个事件已经发生了，而await方法等待计数器达到零，这表示所有需要等待的时间都已经发生。如果计数器值非零，那么await会一直阻塞直到计数器为零，或者等待线程中断，或者等待超时。12345678910111213141516171819202122232425262728public class TestHarness &#123; public long timeTasks(int nThreads, final Runnable task) throws InterruptedException &#123; final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThreads); for (int i = 0; i &lt; nThreads; i++) &#123; Thread t = new Thread(() -&gt; &#123; try &#123; startGate.await(); try &#123; task.run(); &#125; finally &#123; endGate.countDown(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); t.start(); &#125; long start = System.nanoTime(); startGate.countDown(); endGate.await(); long end = System.nanoTime(); return end - start; &#125;&#125;用于测试n个线程并发执行某个任务是需要的时间，如果在创建线程后立即启动他们，那么先启动的线程会领先后启动的线程，并且活跃线程数量会随着时间的推移而增加或减少，竞争程度也在不断发生变化。启动门将使得主线程能够同时释放所有的工作线程，而结束门则使主线程能够等待最后一个线程执行完成，而不是顺序等待每个线程执行完成。FutureTaskFutureTask也可以用作闭锁，表示一种抽象的可生成结果的计算。FutureTask表示的计算是通过Callable来实现，相当于一种可生成结果的Runnable，并且可以处于以下3种状态：等待运行、正在运行和运行完成。当FutureTask进入完成状态之后，它会永远停止在这个状态。Future.get的行为取决于任务的状态，如果任务已经完成，那么可以立即返回结果，否则将阻塞直到任务进入完成状态，然后返回结果或者抛出异常。FutureTask将计算结果从执行计算的线程传递到获取这个结果的线程，而FutureTask的规范确保了这种传递过程能实现结果的安全发布。Callable表示的任务可抛出受检查的或未受检查的异常，并且任何代码都可能抛出一个Error。无论任务代码抛出什么异常，都会封装到一个ExecutionException中，并在Future.get中被重新抛出。信号量计数信号量（Counting Semaphore）用来控制同时访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。计数信号量还可以用来实现某种资源池，或者对容器施加边界。Semaphore中管理着一组虚拟的许可（permit），许可的初始数量可通过构造函数来指定。在执行操作时候可以首先获得许可（只要还有剩余的许可），并在使用以后释放许可。如果没有许可，acquire将阻塞直到有许可。release方法将返回一个许可给信号量。计算信号量的一种简化形式是二值信号量，即初始值为1的Semaphore。二值信号量可以用作互斥体（mutex），并具备不可重入的加锁语义：谁拥有这个许可，谁就拥有了互斥锁。123456789101112131415161718192021222324252627282930public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;(bound)); this.sem = new Semaphore(bound); &#125; public boolean add(T o) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(o); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(T o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125;栅栏栅栏（Barrier）类似于闭锁，他能阻塞一组线程直到某个事件发生。栅栏与闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。栅栏用于实现一些协议，例如几个家庭决定要在某个地方集合：“所有人6:00在麦当劳碰头，到了以后要等其他人，之后在讨论下一步要做的事情”。CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集，他在并行迭代算法中非常有用：这种算法通常将一个问题拆分成一系列互相独立的子问题。当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有线程都到达了栅栏位置，那么栅栏将打开，此时所有的线程将释放，而栅栏将被重置以便下次使用。构建高效且可伸缩的结果缓存12345678910111213141516171819202122232425262728293031323334public class Memoizer&lt;A, V&gt; implements Function&lt;A, V&gt; &#123; private final ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt; cache = new ConcurrentHashMap&lt;&gt;(); private final Function&lt;A, V&gt; func; public Memoizer(Function&lt;A, V&gt; func) &#123; this.func = func; &#125; @Override public V apply(A arg) &#123; while (true) &#123; Future&lt;V&gt; f = cache.get(arg); if (f == null) &#123; FutureTask&lt;V&gt; futureTask = new FutureTask&lt;V&gt;(() -&gt; func.apply(arg)); f = cache.putIfAbsent(arg, futureTask); if (f == null) &#123; f = futureTask; futureTask.run(); &#125; &#125; try &#123; return f.get(); &#125; catch (CancellationException e) &#123; cache.remove(arg, f); &#125; catch (InterruptedException e) &#123; &#125; catch (ExecutionException e) &#123; //other &#125; &#125; &#125;&#125;","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.vibrancy.cn/categories/多线程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.vibrancy.cn/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://www.vibrancy.cn/tags/多线程/"}]},{"title":"8大经典排序算法总结","slug":"classic-sort","date":"2017-05-14T00:08:29.000Z","updated":"2017-06-13T11:49:58.542Z","comments":true,"path":"repository/classic-sort.html","link":"","permalink":"http://www.vibrancy.cn/repository/classic-sort.html","excerpt":"","text":"插入排序直接插入排序排序思想按照索引顺序，每一步将该索引上的值插入到前面已经有序的一组的值适当位置（通过从当前索引处往前的挨个比较）上，直到全部插入为止，详细算法步骤如下：从第一个元素开始，该元素可以认为已经被排序；取出下一个X元素，在已经排序的元素序列中从后向前扫描；如果扫描到的元素（已排序）大于X元素，将该元素往后移动一个位置；重复步骤3，直到找到已排序的元素小于或者等于X元素的位置；将X元素插入到该位置；重复步骤2~4。排序演示代码实现123456789101112public static class StraightInsertSort &#123; public static void sort(int[] e) &#123; int j; for (int i = 1; i &lt; e.length; i++) &#123; int x = e[i]; for (j = i - 1; j &gt;= 0 &amp;&amp; e[j] &gt; x; j--) &#123; e[j + 1] = e[j]; &#125; e[j + 1] = x; &#125; &#125;&#125;结论当输入数据以反序输入时，直接插入排序的时间复杂度为\\(O(N^2)\\)，因为由于嵌套循环的每一个都花费N次迭代；当输入数据已预先排序，直接插入排序的时间复杂度为\\(O(N)\\)，因为内层的for循环的检测总是立即判定不成立而终止。直接插入排序适合数据量比较小的排序应用；逆序数也正好是需要由插入排序执行的交换次数，而一个排过序的数组没有逆序。当输入数据是34,8,64,51,32,21时，该数据有9个逆序，即(34,8),(34,32),(34,21),(64,51),(64,32),(64,21),(51,32),(51,21)以及(32,21)。由于算法还有\\(O(N)\\)量的其他工作，因此插入排序的运行时间是\\(O(I+N)\\)，其中I为原始数组中的逆序数。于是，若逆序数是\\(O(N)\\)，则插入排序以线性时间运行。N个互异数的数组的平均逆序数是\\(N(N-1)/4\\)；通过交换相邻元素进行排序的任何算法平均时间复杂度都需要\\(O(N^2)\\)，也就是说，为了使一个排序算法以\\(O(N^2)\\)时间运行，必须执行一些比较，特别是要对相距较远的元素进行交换。一个排序算法通过删除逆序得以向前进行，而为了有效的进行，他必须使每次交换删除不止一个逆序。二分插入排序排序思想按照索引顺序，每一步将该索引上的值插入到前面已经有序的一组的值适当位置（通过二分查找法找到，可以减少比较次数）上，直到全部插入为止。代码实现12345678910111213141516171819202122232425public static class BinaryInsertSort &#123; public static void sort(int[] array) &#123; int left, current, mid, right; for (int i = 1; i &lt; array.length; i++) &#123; current = array[i]; left = 0; right = i - 1; while (left &lt;= right) &#123; mid = (left + right) / 2; if (current &gt; array[mid]) &#123; left = mid + 1; &#125; else &#123; right = mid - 1; &#125; &#125; for (int k = i - 1; k &gt;= left; k--) &#123; array[k + 1] = array[k]; &#125; if (left != i) &#123; array[left] = current; &#125; &#125; &#125;&#125;结论当N比较大时，二分插入排序的比较次数比直接插入排序的最差情况（反序）要好得多，但是比直接插入排序的最好情况（基本有序）要差。当元素初始序列接近有序时，直接插入排序比二分插入排序的比较次数少。二分插入排序元素移动次数与直接插入排序相同，依赖于元素的初始序列。希尔排序排序思想希尔排序通过将比较的全部元素分为几个区域来提升插入排序的性能，这样可以让一个元素可以一次性地朝最终位置前进一大步。然后算法再取越来越小的步长进行排序，算法的最后一步就是普通的插入排序，但到了这一步，数据几乎已经排好序。排序演示代码实现123456789101112131415public static class ShellSort &#123; public static void sort(int[] e) &#123; for (int gap = e.length / 2; gap &gt; 0; gap /= 2) &#123; int j; for (int i = gap; i &lt; e.length; i++) &#123; int current = e[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; e[j] &gt; current; j -= gap) &#123; e[j + gap] = e[j]; &#125; e[j + gap] = current; &#125; &#125; &#125;&#125;结论如果有一个很小的数据在一个已按升序排好序的数组的末端，如果用复杂度为\\(O(N^2)\\)的排序算法（冒泡排序或直接插入排序），可能会进行n次的比较和交换才能将该数据移至正确的位置。而希尔排序会用较大的步长移动数据，所以小数据只需要进行少数比较和交换即可到正确位置。使用增量序列\\(h_k\\)进行一趟排序后，对于每个i我们都有\\(a[i]&lt;=a[i+h_k]\\)，所有相隔\\(h_k\\)的元素都被排序，此时称文件时\\(h_k\\)排序的。\\(h_k\\)排序的实质就是，将\\(h_k\\)，\\(h_k+1\\)，···，\\(N-1\\)中的每个位置i，把该位置对应的元素放到\\(i-{h_k}\\)中的正确位置上。一趟\\(h_k\\)排序的作用就是对\\(h_k\\)个独立的子数组执行一次插入排序。一个\\(hk\\)排序的文件（然后是\\(h{k-1}\\)排序）会一直保持它的\\(h_k\\)排序性，前面各趟排序的成果不会被后面的排序打乱。希尔排序不是稳定的排序算法虽然一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性将会被打乱。比如序列{ 3, 5, 10, 8, 7, 2, 8, 1, 20, 6 }h=2时分成两个子序列 { 3, 10, 7, 8, 20 } 和 { 5, 8, 2, 1, 6 } ，未排序之前第二个子序列中的8在前面，现在对两个子序列进行插入排序，得到 { 3, 7, 8, 10, 20 } 和 { 1, 2, 5, 6, 8 } ，即 { 3, 1, 7, 2, 8, 5, 10, 6, 20, 8 } ，两个8的相对次序发生了改变。选择排序简单选择排序排序思想按照索引顺序，每趟会在该索引后的元素中找出一个最小元素与当前索引处的元素进行交换。排序演示简单排序过程示例动图演示代码实现12345678910111213141516public static class SimpleSelectSort &#123; public static void sort(int[] array) &#123; for (int i = 0; i &lt; array.length; i++) &#123; int minValue = array[i]; int minIndex = i; for (int j = i + 1; j &lt; array.length; j++) &#123; if (array[j] &lt; minValue) &#123; minValue = array[j]; minIndex = j; &#125; &#125; array[minIndex] = array[i]; array[i] = minValue; &#125; &#125;&#125;结论简单选择排序的时间复杂度都为\\(O(N^2)\\)；是不稳定的排序算法简单选择排序的改进将每趟循环可以确定两个元素（最大和最小值），从而减少排序所需的循环次数。 改进后对\\(N\\)个数据进行排序，最多只需进行\\(N/2\\)趟即可12345678910111213141516171819public class SimpleSelectSort&#123; public static void sort2(int[] array) &#123; for (int i = 1, min, max, len = array.length; i &lt;= len / 2; i++) &#123; min = max = i; for (int j = i + 1; j &lt;= len - i; j++) &#123; if (array[j] &gt; array[max]) &#123; max = j; continue; &#125; if (array[j] &lt; array[min]) &#123; min = j; &#125; &#125; //该交换操作还可分情况讨论以提高效率 Utils.swap(array, min, i - 1); Utils.swap(array, max, len - i); &#125; &#125;&#125;堆排序排序思想优先队列可以用于以O(NlogN)时间来排序，基于该思想的算法叫做堆排序heapsort。在建立N个元素的二叉堆时，该阶段花费\\(O(N)\\)时间，然后又执行N次deleteMin操作，由于每个deleteMin花费时间\\(O(logN)\\)，因此总运行时间是\\(O(NlogN)\\)。优先队列的算法主要问题在于，它使用了一个附加数组，因此，存储需求增加一倍。但不会太影响时间问题，附加的时间消耗只有\\(O(N)\\)，只是增加了空间复杂度。那么对于以上问题，在堆排序中的解决方案是：在每次deleteMin之后，将堆缩小1。因此，堆中的最后一个单元可以用来存放刚刚删除的元素。使用这种策略，在最后一次deleteMin之后，该数组将以递减的顺序包含这些元素。如果想要排成更典型的递增顺序，那么可以在构建堆的时候建立最大堆。算法演示代码实例12345678910111213141516171819202122232425262728293031323334public static class HeapSort &#123; public static void sort(int[] array) &#123; for (int i = array.length / 2; i &gt;= 0; i--) &#123; percolateDown(array, i, array.length); &#125; for (int i = array.length - 1; i &gt; 0; i--) &#123; Utils.swap(array, 0, i); percolateDown(array, 0, i); &#125; &#125; private static int leftChild(int i) &#123; return 2 * i + 1; &#125; private static void percolateDown(int[] a, int i, int n) &#123; int child; int tmp; for (tmp = a[i]; leftChild(i) &lt; n; i = child) &#123; child = leftChild(i); //找到i孩子节点中最大的一个 if (child != n - 1 &amp;&amp; a[child] &lt; a[child + 1]) &#123; child++;//i的右孩子 &#125; if (tmp &lt; a[child]) &#123;//如果较大的子结点大于父结点 a[i] = a[child]; // 那么把较大的子结点往上移动，替换它的父结点 &#125; else &#123; break; &#125; &#125; a[i] = tmp; &#125;&#125;交换排序冒泡排序排序思想通过交换使相邻的两个数变成小数在前大数在后，这样每次遍历后，最大的数就“沉”到最后面了，重复N次即可以使数组有序。排序演示动图演示排序过程示意图代码实现123456789101112public static class BubbleSort &#123; public static void sort(int[] array) &#123; for (int i = 0; i &lt; array.length; i++) &#123; // j &lt; array.length - i - 1 意思是后面的已经有序，不需要在判断 for (int j = 0; j &lt; array.length - i - 1; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; Utils.swap(array, j, j + 1); &#125; &#125; &#125; &#125;&#125;结论冒泡排序是基于比较的算法，时间复杂度为\\(O(N^2)\\)，只有在n比较小的时候性能才比较好。冒泡排序算法改进设置一个标志性变量pos，用于记录每趟排序中最后一次进行交换的位置。由于pos之后的记录均已交换到位，因此在下一趟排序时只要扫描到pos位置即可。1234567891011121314public class BubbleSort &#123; public static void sort1(int[] array) &#123; for (int i = array.length - 1; i &gt; 0; ) &#123; int pos = 0; for (int j = 0; j &lt; i; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; pos = j; Utils.swap(array, j, j + 1); &#125; &#125; i = pos; &#125; &#125;&#125;传统冒泡排序在每趟的操作中只能找到一个最大值或最小值，因此，考虑利用在每趟排序中进行正向和反向的两边冒泡方法一次可以得到两个最终值（最大值和最小值），从而使排序趟数几乎减少一半。123456789101112131415161718192021public class BubbleSort &#123; public static void sort2(int[] array) &#123; int low = 0; int high = array.length - 1; while (low &lt; high) &#123; for (int i = low; i &lt; high; i++) &#123; if (array[i] &gt; array[i + 1]) &#123; Utils.swap(array, i, i + 1); &#125; &#125; high--; for (int i = high; i &gt; low; i--) &#123; if (array[i] &lt; array[i - 1]) &#123; Utils.swap(array, i, i - 1); &#125; &#125; low++; &#125; &#125;&#125;快速排序排序思想选取一个基准pivot元素，通常选择第一个元素或者最后一个元素；进行分区partition操作，通过一趟排序将待排序的记录分割成两个部分，其中一个部分的元素均比基准元素小，另一部分元素均比基准元素大；对每个分区递归地进行步骤1~3，递归的结束条件是子序列的大小是0或1，这时整体已经排好序。排序演示动图演示排序过程代码实现123456789101112131415161718192021222324252627public class QuickSort&#123; public static void sort(int[] array) &#123; quickSort(array, 0, array.length - 1); &#125; private static void quickSort(int[] array, int low, int high) &#123; if (low &lt; high) &#123; int pivot = partition(array, low, high); quickSort(array, 0, pivot - 1); quickSort(array, pivot + 1, high); &#125; &#125; private static int partition(int[] array, int low, int high) &#123; for (int pivot = array[low]; low &lt; high; ) &#123; while (low &lt; high &amp;&amp; array[high] &gt;= pivot) &#123; high--; &#125; Utils.swap(array, low, high); while (low &lt; high &amp;&amp; array[low] &lt;= pivot) &#123; low++; &#125; Utils.swap(array, low, high); &#125; return low; &#125;&#125;结论最坏的情况下，也就是每次选取的基准都是最大或最小的元素（例如，在上例7,8,10,9中），导致每次只划分出了一个子序列，需要进行n-1次划分才能结束递归，时间复杂度为O(n^2)；最好的情况下，每次选取的基准都能均匀划分，只需要logN次划分就能结束递归，时间复杂度为O(logN)。平均情况下，需要的时间复杂度为O(NlogN)。快速排序不是稳定的排序算法。快速排序算法改进快速排序通常被认为在同数量级\\(O(NlogN)\\)的排序方法中性能最好的，若初始序列已经基本有序，快排反而退化为冒泡排序。在改进的算法中，只对长度大于k的子序列递归调用快速排序，让原序列基本有序，然后再对整个基本有序的序列使用直接插入排序。实践证明，改进后的算法时间复杂度有所降低，且当k取8左右的时候，改进算法的性能最优。12345678910111213141516171819202122232425262728public class QuickSort&#123; public static void sort(int[] array, int k) &#123; quickSortImprove(array, 0, array.length - 1, k); StraightInsertSort.sort(array); &#125; private static void quickSortImprove(int[] array, int low, int high, int k) &#123; if (high - low &gt; k) &#123; int pivot = partition(array, low, high); quickSortImprove(array, 0, pivot - 1, k); quickSortImprove(array, pivot + 1, high, k); &#125; &#125; private static int partition(int[] array, int low, int high) &#123; for (int pivot = array[low]; low &lt; high; ) &#123;//从表的两端交替地向中间扫描 while (low &lt; high &amp;&amp; array[high] &gt;= pivot) &#123; //从high 所指位置向前搜索，至多到low+1 位置。将比基准元素小的交换到低端 high--; &#125; Utils.swap(array, low, high); while (low &lt; high &amp;&amp; array[low] &lt;= pivot) &#123; low++; &#125; Utils.swap(array, low, high); &#125; return low; &#125;&#125;归并排序递归实现排序思想归并排序是采用分治法的一个非常典型的应用，归并排序的思想就是先递归分解数组，再合并数组。先考虑合并两个有序数组，基本思路是两个输入数组A和B，一个输出数组C，以及3个计数器ai、bi、ci，他们的初始置于对应数组的开始端。A[ai]和B[bi]中的最小者被拷贝到C中的下一个位置，相关的计数器向前推进一步。当两个输入表有一个用完时，则将另一个表剩余部分拷贝到C中。再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面的合并数组方式将这两个数组合并排序。如何让这两个数组内部有序？可以再二分，直至分解出的小组含有一个元素为止，此时认为该小组内部已有序，然后合并排序相邻两个小组即可。排序演示动图演示排序过程12345678910111213141516171819202122232425262728293031323334353637383940before sort= 5 9 4 3 2 6 10 1 7 8 -------------------left[0:0] = 5 ====&gt; 5 9 0 0 0 0 0 0 0 0 right[1:1] = 9 -------------------left[0:1] = 5 9 ====&gt; 4 5 9 0 0 0 0 0 0 0 right[2:2] = 4 -------------------left[3:3] = 3 ====&gt; 4 5 9 2 3 0 0 0 0 0 right[4:4] = 2 -------------------left[0:2] = 4 5 9 ====&gt; 2 3 4 5 9 0 0 0 0 0 right[3:4] = 2 3 -------------------left[5:5] = 6 ====&gt; 2 3 4 5 9 6 10 0 0 0 right[6:6] = 10 -------------------left[5:6] = 6 10 ====&gt; 2 3 4 5 9 1 6 10 0 0 right[7:7] = 1 -------------------left[8:8] = 7 ====&gt; 2 3 4 5 9 1 6 10 7 8 right[9:9] = 8 -------------------left[5:7] = 1 6 10 ====&gt; 2 3 4 5 9 1 6 7 8 10right[8:9] = 7 8 -------------------left[0:4] = 2 3 4 5 9 ====&gt; 1 2 3 4 5 6 7 8 9 10 right[5:9] = 1 6 7 8 10 -------------------after sort = 1 2 3 4 5 6 7 8 9 10代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243public class MergeSort &#123; public static void sort(int[] array) &#123; int[] tmpArray = new int[array.length]; sort(array, tmpArray, 0, array.length - 1); &#125; private static void sort(int[] array, int[] tmp, int left, int right) &#123; if (left &lt; right) &#123; int center = (left + right) / 2; sort(array, tmp, left, center); sort(array, tmp, center + 1, right); merge(array, tmp, left, center + 1, right); &#125; &#125; private static void merge(int[] array, int[] tmpArray, int leftStart, int rightStart, int rightEnd) &#123; int leftEnd = rightStart - 1; int tmpStart = leftStart; int numElements = rightEnd - leftStart + 1; while (leftStart &lt;= leftEnd &amp;&amp; rightStart &lt;= rightEnd) &#123; if (array[leftStart] &lt;= array[rightStart]) &#123; tmpArray[tmpStart++] = array[leftStart++]; &#125; else &#123; tmpArray[tmpStart++] = array[rightStart++]; &#125; &#125; /*将left剩余元素复制到tmp中*/ while (leftStart &lt;= leftEnd) &#123; tmpArray[tmpStart++] = array[leftStart++]; &#125; /*将right剩余元素复制到tmp中*/ while (rightStart &lt;= rightEnd) &#123; tmpArray[tmpStart++] = array[rightStart++]; &#125; for (int i = 0; i &lt; numElements; i++, rightEnd--) &#123; array[rightEnd] = tmpArray[rightEnd]; &#125; &#125;&#125;结论归并排序是经典的分治策略，它将问题分（divide）成一些小问题然后递归求解，而治（conquer）的阶段则将分的阶段解得的各答案修补在一起。最差的情况下，归并排序的运行时间是\\(O(NlogN)\\)，但是有一个明显的问题，整个算法还要花费将数据拷贝到临时数组再拷贝回来这样一个附加的工作，明显减慢了排序的速度。归并排序使用所有流行排序算法中最少的比较次数。非递归实现排序思想将数组中的相邻元素两两配对，构成\\(N/2\\)个长度为2的排好序的子数组，然后再将他们排序成长度为4的子数组段，如此下去，直至整个数组排好序。排序演示代码实现12345678910111213141516171819202122232425262728public class MergeSort &#123; /** * 非递归排序 */ public static void sort2(int[] array) &#123; int[] tmp = new int[array.length]; for (int gap = 1, len = array.length, tmpIndex, leftStart, leftEnd, rightStart, rightEnd; gap &lt; len; gap *= 2) &#123; for (tmpIndex = 0, leftStart = 0; leftStart &lt; len - gap; leftStart = rightEnd) &#123; if ((rightEnd = ((rightStart = leftEnd = leftStart + gap) + gap)) &gt; len) &#123; rightEnd = len; &#125; while (leftStart &lt; leftEnd &amp;&amp; rightStart &lt; rightEnd) &#123; tmp[tmpIndex++] = array[leftStart] &gt; array[rightStart] ? array[rightStart++] : array[leftStart++]; &#125; while (leftStart &lt; leftEnd) &#123; array[--rightStart] = array[--leftEnd]; &#125; while (tmpIndex &gt; 0) &#123; array[--rightStart] = tmp[--tmpIndex]; &#125; &#125; &#125; &#125;&#125;排序综合比较名称最差时间复杂度最优时间复杂度平均时间复杂度辅助空间稳定性直接插入排序\\(O(N^2)\\)\\(O(N)\\)\\(O(N^2)\\)\\(O(1)\\)稳定二分插入排序\\(O(N^2)\\)\\(O(NlogN)\\)\\(O(N^2)\\)\\(O(1)\\)稳定希尔排序\\(O(N^2)\\)\\(O(N)\\)\\(O(NlogN)-O(N^2)\\)\\(O(1)\\)不稳定简单选择排序\\(O(N^2)\\)\\(O(N^{1.3})\\)\\(O(NlogN)-O(N^2)\\)\\(O(1)\\)不稳定堆排序\\(O(NlogN)\\)\\(O(NlogN)\\)\\(O(NlogN)\\)\\(O(1)\\)不稳定冒泡排序\\(O(N^2)\\)\\(O(N)\\)\\(O(N^2)\\)\\(O(1)\\)稳定快排序\\(O(N^2)\\)\\(O(NlogN)\\)\\(O(NlogN)\\)\\(O(logN)-O(N)\\)不稳定归并排序\\(O(NlogN)\\)\\(O(NlogN)\\)\\(O(NlogN)\\)\\(O(N)\\)稳定计数排序\\(O(N+K)\\)\\(O(N+K)\\)\\(O(N+K)\\)\\(O(K)\\)稳定参考资料常用排序算法总结（性能+代码）经典排序算法总结与实现白话经典算法系列排序算法可视化所谓堆和堆排序几种经典排序算法三种线性排序算法 计数排序、桶排序与基数排序","categories":[{"name":"算法","slug":"算法","permalink":"http://www.vibrancy.cn/categories/算法/"}],"tags":[{"name":"8大排序算法","slug":"8大排序算法","permalink":"http://www.vibrancy.cn/tags/8大排序算法/"}]},{"title":"Java8 HashMap原理分析","slug":"java8-HashMap-principle-analysis","date":"2017-05-03T04:55:16.000Z","updated":"2017-05-15T11:56:10.510Z","comments":true,"path":"repository/java8-HashMap-principle-analysis.html","link":"","permalink":"http://www.vibrancy.cn/repository/java8-HashMap-principle-analysis.html","excerpt":"","text":"简介特性它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。映射中的key是不可变对象，不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。类继承关系图内部实现几个重要的属性123456transient Node&lt;K, V&gt;[] table; int threshold;final float loadFactor;transient int size; transient int modCount;static final int TREEIFY_THRESHOLD = 8;table哈希桶数组初始化长度length默认为16，长度必须为2的n次方（合数）。常规设计是把length设计为素数，来减少hash冲突的概率。而HashMap在此是为了在取模和扩容的时候做优化，同时也为了减少冲突。loadFactor负载因子，是table中元素数量和table长度的比值。默认值是0.75thresholdHashMap所能容纳的最大数据量的Node(键值对)个数；计算公式：threshold = table.length * loadFactor，结合公式可知，threshold是负载因子和数组长度对应下允许的最大元素数目，如果超过这个数目，那么就得重新扩容（resize），扩容后的容量是之前容量的2倍。如果内存空间大而又对时间效率要求很高，可以降低负载因子Load factor的值。如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。sizeHashMap中实际存在的键值对数量；注意与table.length、threshold的区别。modCount记录HashMap内部结构发生变化的次数；用于迭代的快速失败。TREEIFY_THRESHOLD链表转红黑树的长度阈值。存储结构从结构实现来讲，HashMap是数组+链表+红黑树来实现的。从源码可知，HashMap类中有一个非常重要的字段，就是Node[] table，即上图中的哈希桶数组table，是一个Node类型的数组。123456static class Node&lt;K, V&gt; implements Map.Entry&lt;K, V&gt; &#123; final int hash; //用来定位数组索引的位置 final K key; V value; Node&lt;K, V&gt; next;&#125;Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)，上图中的每个黑色圆点就是一个Node对象。HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法，链地址法简单来说，就是数组加链表的结合。在每个数组元素上都对应一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。如果哈希桶数组很大，即使较差的Hash算法也会比较分散；如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡。其实就是根据实际情况实行哈希数组的扩容或收缩，并在此基础上设计好的hash算法减少Hash碰撞。负载因子和Hash算法设计的再合理，也免不了会出现链表过长的情况，一旦链表过长，则会严重影响HashMap的性能。当链表长度太长（默认超过TREEIFY_THRESHOLD）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。核心方法分析根据键值计算哈希桶数组的索引123456789101112131415161718/**** 根据key计算hash值*/static final int hash(Object key) &#123; int h; // h = key.hashCode(); 第一步、取 kek的hashCode值 // h ^ (h &gt;&gt;&gt; 16) 第二步、取hash的高位与hash参与异或运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/*** 根据hash值和数组长度，计算key在table中的索引。* JDK8 中没有该方法，它直接在方法内部计算 hash &amp; (length - 1) 的值*/private static int indexFor(int hash, int length) &#123; return hash &amp; (length - 1);&#125;不管是增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。对于任意给定的对象，只要hashCode相同，那么hash()方法返回的hash值总是相同的。一般情况下，将hash值与数组长度进行取模运算来得到数组索引，但是取模运算的消耗还是比较大的。在HashMap中，通过indexFor()方法来计算索引。indexFor()方法非常的巧妙，通过hash &amp; (length-1)得到对象的保存位置。因为HashMap底层数组的长度总是2的n次方，这时hash &amp; (length-1)运算等价于hash对length的取模，&amp;比%具有更高的效率。画图说明hash()和indexFor()的运算过程:put方法put()流程源码如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; p; int n, i; //table 是否为空 或者 长度为0 if ((tab = table) == null || (n = tab.length) == 0) &#123; // resize 重新扩容 n = (tab = resize()).length; &#125; //如果当前table索引上的值为空 if ((p = tab[i = hash &amp; (n - 1)]) == null) //直接将值插入 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K, V&gt; e; K k; // 如果 key 并且 hash 相同 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;//直接覆盖value else if (p instanceof TreeNode) //如果是红黑树，则直接在树中插入键值对 e = ((TreeNode&lt;K, V&gt;) p).putTreeVal(this, tab, hash, key, value); else &#123; //开始循环，遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //到了链表末尾 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //链表长度大于8转换为红黑树进行处理 treeifyBin(tab, hash); break; &#125; // 如果 key 并且 hash 相同 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //直接覆盖value break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) //超过最大容量 就扩容 resize(); afterNodeInsertion(evict); return null;&#125;扩容机制扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。下面举个例子说明下扩容过程：123456789public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;(2); printInfo(map, &quot;初始化HashMap的信息为：&quot;); int[] values = &#123;3, 7, 5, 9&#125;; for (int i = 0; i &lt; values.length; i++) &#123; map.put(values[i], &quot;v&quot;); printInfo(map, String.format(&quot;添加第%d个元素[%s=%s]后的info：&quot;, i + 1, values[i], &quot;v&quot;)); &#125;&#125;运行结果如下图所示：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657初始化HashMap的信息为：size: 0tableLength: 0loadFactor: 0.75threshold: 2modCount: 0table: null添加第1个元素[3=v]后的info：size: 1tableLength: 2loadFactor: 0.75threshold: 1modCount: 1table: 索引 | 元素 0 | null 1 | [3=v]添加第2个元素[7=v]扩容后的info：size: 2tableLength: 4loadFactor: 0.75threshold: 3modCount: 2table: 索引 | 元素 0 | null 1 | null 2 | null 3 | [3=v] --&gt; [7=v]添加第3个元素[5=v]后的info：size: 3tableLength: 4loadFactor: 0.75threshold: 3modCount: 3table: 索引 | 元素 0 | null 1 | [5=v] 2 | null 3 | [3=v] --&gt; [7=v]添加第4个元素[9=v]扩容后的info：size: 4tableLength: 8loadFactor: 0.75threshold: 6modCount: 4table: 索引 | 元素 0 | null 1 | [9=v] 2 | null 3 | [3=v] 4 | null 5 | [5=v] 6 | null 7 | [7=v]经过观测可发现，HashMap的table数组长度使用的是2次幂的扩展（长度扩展为原来2倍），数组扩展后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置，扩展后对于元素新位置的判断对应的源码为：123456789101112131415161718192021222324252627282930HashMap.resize():Node&lt;K,V&gt; loHead = null, loTail = null;Node&lt;K,V&gt; hiHead = null, hiTail = null;Node&lt;K,V&gt; next;do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125;&#125; while ((e = next) != null);if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead;&#125;if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead;&#125;接下来以添加第4个元素之后进行扩容的过程分析一下上面代码的原理以上4个元素的hash值分别为：| key | hash || :—: | :—: || 3 | 3 || 7 | 7 || 5 | 5 || 9 | 9 |当把第4个元素[9=v]添加进map之后，未扩容（未执行resize()）前的table为：12345table: 索引 | 元素 0 | null 1 | [5=v] --&gt; [9=v] 2 | null 3 | [3=v] --&gt; [7=v]这时由于++size &gt; threashold ==&gt; 4&gt;3 ，所以需要执行resize()方法该过程为新建一个长度为原来2倍的数组，如果判断原来数组上的node是一个链表，那么会遍历链表，判断每个元素的(e.hash &amp; oldCap)的值是否为0，来决定链表中元素的新位置| key | hash | (e.hash &amp; oldCap) | 是否为0 | 新索引 || :—: | :—: | :—————: | :—–: | :—-: || 3 | 3 | 0 | 是 | 3 || 7 | 7 | 4 | 否 | 3+4 || 5 | 5 | 4 | 是 | 1+4 || 9 | 9 | 0 | 否 | 1 |根据上表的统计可以得出结论，如果e.hash &amp; oldCap为0，则位置索引不变；否则新的索引是原位置索引+oldCap的，那么扩容后的table为：123456789table: 索引 | 元素 0 | null 1 | [9=v] 2 | null 3 | [3=v] 4 | null 5 | [5=v] 6 | null 7 | [7=v]该判断是JDK8的一个优化，不需要像JDK7那样重新计算hash，只需要判断元素的hash值与oldCap的与运算结果就好了。这样的设计省去了重新计算hash值的时间，并且能够均匀的把冲突的节点分散到新的table中去。另外，JDK8的HashMap在迁移链表的时候会保持链表元素的顺序不变。resize()方法的全部代码如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970final Node&lt;K, V&gt;[] resize() &#123; Node&lt;K, V&gt;[] oldTab = table; int oldCapacity = (oldTab == null) ? 0 : oldTab.length; int oldThreshold = threshold; int newCapacity, newThreshold = 0; if (oldCapacity &gt; 0) &#123; if (oldCapacity &gt;= MAXIMUM_CAPACITY) &#123;//扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE;//修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return oldTab; &#125; else if ((newCapacity = oldCapacity &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCapacity &gt;= DEFAULT_INITIAL_CAPACITY) newThreshold = oldThreshold &lt;&lt; 1; // 将容量和阈值在原来的基础上扩大2倍 &#125; else if (oldThreshold &gt; 0) // initial capacity was placed in threshold newCapacity = oldThreshold; else &#123; // zero initial threshold signifies using defaults newCapacity = DEFAULT_INITIAL_CAPACITY; newThreshold = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThreshold == 0) &#123; float ft = (float) newCapacity * loadFactor; newThreshold = (newCapacity &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE);//修改阈值 &#125; threshold = newThreshold; @SuppressWarnings(&#123;&quot;rawtypes&quot;, &quot;unchecked&quot;&#125;) Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCapacity]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCapacity; ++j) &#123;//遍历原来的哈希表数组 Node&lt;K, V&gt; current; if ((current = oldTab[j]) != null) &#123; oldTab[j] = null;//清空 if (current.next == null)//如果当前节点只有一个节点 newTab[current.hash &amp; (newCapacity - 1)] = current; else if (current instanceof TreeNode)//如果当前节点是红黑树 ((TreeNode&lt;K, V&gt;) current).split(this, newTab, j, oldCapacity); else &#123; // 当前是链表 ，保留顺序preserve order Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; do &#123; next = current.next; if ((current.hash &amp; oldCapacity) == 0) &#123; if (loTail == null) loHead = current; else loTail.next = current; loTail = current; &#125; else &#123; if (hiTail == null) hiHead = current; else hiTail.next = current; hiTail = current; &#125; &#125; while ((current = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCapacity] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;线程安全性并发的rehash过程在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，因为在并发的多线程使用场景中使用HashMap可能造成数据丢失。多线程测试HashMap的代码1234567891011121314151617181920212223public static void main(String[] args) &#123; HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;(2, 0.75f); AtomicInteger counter = new AtomicInteger(0); map.put(5, &quot;C&quot;); Runnable r1 = () -&gt; &#123; map.put(7, &quot;B&quot;); counter.incrementAndGet(); &#125;; Runnable r2 = () -&gt; &#123; map.put(3, &quot;A&quot;); map.put(8, &quot;A&quot;); counter.incrementAndGet(); &#125;; new Thread(r1, &quot;thread1&quot;).start(); new Thread(r2, &quot;thread2&quot;).start(); while (true) &#123; if (counter.get() == 2) &#123; printInfo(map, &quot;&quot;); System.out.println(map.get(7)); break; &#125; &#125;&#125;通过阻塞thread1的resize()，再让thread2执行，并进行resize()操作之后，最后打印的结果为：12345678910111213141516size: 4tableLength: 8loadFactor: 0.75threshold: 6modCount: 4table:索引 | 元素 0 | [8=A] 1 | null 2 | null 3 | [3=A] 4 | null 5 | null 6 | null 7 | nullnull可见table的size为4，表明map经历了4次put过程，而实际上却只有两个元素，其他元素丢失了，那么接下来通过IntellijIdea的多线程断点调试来演示一下元素为什么丢失。初始化一个调试环境用debug调试模拟多线程切换的流程点击debug按钮，这时断点会走到thread1处；将HashMap.resize(){next=e.next}处打上断点，并设置挂起模式为thread。接着开始执行thread1，这时thread1线程会停到刚才的断点处，相当于挂起thread1。切换到thread2，并取消第2步设置的断点，让thread2能够一次性运行结束，并进行resize()过程。thread2线程执行结束后，唤醒thread1，让thread1继续执行。最后，通过打印的结果可知，数据丢失了。分析通过分析resize()的源码可知，每次是让table指向一个newTab123456······threshold = newThr;@SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];table = newTab;······接着遍历oldTab，将原有的key-value存到newTab中。12345678910111213for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123;······if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead;&#125;if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead;&#125;在上面的第三步，thread1执行到next = e.next这挂起，接着唤醒thread2去执行，thread2把[8=A]放进map之后，也会执行resize()操作，这时会将 table 指向一个新的newTab，那么thread1的newTab将会失去引用，所以之前存储的值也就丢失了。解决方案因此，在多线程环境中，使用ConcurrentHashMap替换HashMap，或者使用Collections.synchronizedMap将HashMap包装起来。JDK8和JDK7的HashMap性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。Hash比较均匀的情况编写一个Key类123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125;这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同。创建Keys类，用于缓存Key，避免频繁的GC，而影响HashMap实际查找值的时间。123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125;开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……、10000000）1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125;在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响，结果如下：hash极不均匀的情况假设我们有一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下：123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125;仍然执行main方法，得出的结果如下表所示从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，JDK1.8的HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。总结扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。JDK1.8引入红黑树大程度优化了HashMap的性能。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.vibrancy.cn/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.vibrancy.cn/tags/java/"},{"name":"HashMap","slug":"HashMap","permalink":"http://www.vibrancy.cn/tags/HashMap/"},{"name":"红黑树","slug":"红黑树","permalink":"http://www.vibrancy.cn/tags/红黑树/"},{"name":"散列表","slug":"散列表","permalink":"http://www.vibrancy.cn/tags/散列表/"}]},{"title":"Android增量更新：服务器篇","slug":"android-incremental-update-server-articles","date":"2017-04-30T13:40:21.000Z","updated":"2017-05-15T11:56:10.571Z","comments":true,"path":"repository/android-incremental-update-server-articles.html","link":"","permalink":"http://www.vibrancy.cn/repository/android-incremental-update-server-articles.html","excerpt":"","text":"增量更新的原理其实增量升级的原理很简单，即首先将应用的旧版本Apk与新版本Apk做差分，得到更新的部分的补丁，例如旧版本的APK有5M，新版的有8M，更新的部分则可能只有3M左右(这里需要说明的是，得到的差分包大小并不是简单的相减，因为其实需要包含一些上下文相关的东西——有时候旧版本10M，新版本8M，得到的差分包可能有5M)，使用差分升级的好处显而易见，那么你不需要下载完整的8M文件，只需要下载更新部分就可以，而更新部分可能只有3、4M，可以很大程度上减少流量的损失。在用户下载了差分包之后，需要在手机端将他们组合起来。可以参考的做法是先将手机端的旧版本软件(多半在/data/下)，复制到SD卡或者cache中，将它们和之前的差分patch进行组合，得到一个新版本的apk应用，如果不出意外的话，这个生成的apk和你之前做差分的apk是一致的。增量更新实现使用的工具使用开源的二进制比较工具bsdiff及其依赖的bzip2下载完后，得到这样的目录结构：其中bsdiff.c用于在服务端生成差分包，bspatch.c用于在客户端把旧版本apk与服务端生成的差分包进行合成为新版本apk。实现的步骤在服务端，生成新旧版本的差分包在客户端，使用已安装的旧版apk与这个差分包，合成为一个新版apk。校验新合成的客户端文件是否完成，签名时候和已安装客户端一致，如一致，提示用户安装;服务端生成差分包简介由于服务器的不同，因此我们需要将以上的c/c++文件，build输出为动态链接库，以供java调用，其中Window环境生成名为libApkPatchLibraryServer.dll文件，Unix/Linux环境生成名为libApkPatchLibraryServer.so，OSX下生成名为libApkPatchLibraryServer.dylib的文件。下面具体讲一下在Windows服务器上怎么生成libApkPatchLibraryServer.dll文件的生成dll动态链接库下载开源工具如果我们要生成dll动态链接库，那我们就不能用刚才下的bsdiff-4.3了（具体原因下面再说），我们需要在这里bsdiff 下载一个针对win32版本的bsdiff文件，下载页面如图所示：下载得到的文件如图所示：里面已经包含了bsdiff.cpp，bspatch.cpp及其依赖的bzlip等文件。改写bsdiff.cpp（生成差分包）首先，在MyEclispe中声明一个native方法，如图所示：接着，为了生成的方便，将该类及完整的所在包复制到桌面上，我们利用javac 和javap命令将该native方法生成c/c++中对应的.h头文件：这时，我们可以看到在桌面上生成了一个com_cwc_smartupdate_util_DiffUtil.h的头文件。打开头文件，如下图所示：以上代码需要说明一下，首先函数名的格式遵循如下规则：Java_包名_类名_方法名。其中，JNIEXPORT、JNICALL、JNIEnv和jobject都是JNI标准中定义的类型或者宏。实现JNI方法这里可以选用c或c++实现，我们这使用的是c++，因为在上文中下载win32版本的bsdiff中的bsdiff.cpp就是用c++实现的，接着我们打开该文件进行改写。（注意：我这以下的所有操作都是基于VS2013，因为涉及到很多c和h文件的引用，如果使用命令行的话，在连接阶段可能出现函数未定义的情况，为了简便本人直接使用了VS2013来生成dll文件）。首先，利用vs2013新建一个dll项目，将bsdiff4.3-win32-src.zip解压得到的文件导入该项目中，并将bsdiff.cpp重新命名为com_cwc_smartupdate_util_DiffUtil.cpp，另外，这里还需要三个头文件，分别是jni.h、jni_md.h（在两个在ndk里面找，可以在该ndk根文件夹子下全文搜索一下）和刚才生成的com_cwc_smartupdate_util_DiffUtil.h，最终得到的目录结构如下：接着我们打开com_cwc_smartupdate_util_DiffUtil.cpp文件，进行我们的改写操作，首先，引入头文件：之后，把typedef long pid_t注释掉，并添加ftello和fseeko两个函数宏定义，如图所示：接着，我们来实现com_cwc_smartupdate_util_DiffUtil.h中的函数，代码如下：这段代码意思是将传入的三个字符串（新旧版本的文件路径和生成的差分包路径）分别放进一个char* 类型的指针数组里面，然后调用appDiff函数，生成差分包。那这个appDiff如何实现呢，我们找到该文件下的main方法，将该main方法重命名为appDiff：接着，把该appDiff函数向下拖动，会看到这段代码，这段代码用于通过打开旧版本文件，将文件的数据读到名为old的内存当中，这段代码改写如下：因为lseek，open等函数都是Linux里面的，如果在window下使用会出现打开文件失败的情况。改写的文件如下，其中stream是新定义的一个FILE* stream;文件类型指针：通过这段代码可以将旧版本文件数据读取到u_char* old中。接着，我们改写读取新文件的这段代码，代码如下：改写成：到此为止，我们的所有操作就全部完成了，接下来我们生成dll文件，在生成的dll文件中也注意是32位的还是64位的，不然在java调用的时候会出现读取失败的情况。在服务端调用dll文件其中，DiffAppServer64就是刚才生成的dll文件，由于DiffAppServer64.dll需要依赖其他的dll文件，我这需要依赖msvcr100d和kernel32，所以在这里也必须将两个文件导入才行。最后，这三个文件放置的位置如图所示：在tomcat根目录下的bin子目录下新建一个appdiff目录，然后把三个文件放到这里。当这些所有的操作完成之后，就可以在服务端生成差分包了。运行效果展示apk文件上传页面面旧版本文件上传新版本文件上传当上传新版本后，服务端后台就自动开始生成差分包的工作了那么又涉及到另外一个问题，由于比较生成差分包在底层进行，并且非常的耗时，大概需要1分多钟，那么如何显示进度，生成差分包的工作进行到哪一步了？这就需要利用jni调用java方法，将底层的信息传到java代码层。jni调用java方法，回传底层的进度信息在声明genDiff 这个native方法的的类中java.cwc.smartupdate.util.DiffUtil声明一个静态的方法：这个方法表示，在c底层进行调用该方法，传递整型state参数，通过对比不同的整型数据，找到底层对应的执行进度。让我们返回到com_cwc_smartupdate_util_DiffUtil.cpp文件中，找到我们在上文中实现的本地方法对应的函数：为了方便演示，在这个函数上面定义一个用于发布进度的函数：这段函数的意思就是通过反射来调用DiffUtil类内的静态方法publishProgress，然后在appDiff函数内部，就可以在关键的地方调用该函数用来发布当前执行任务的状态了，（注意定义的函数需要在该文件头部声明，不然出现找不到函数的错误提示），另外还有一点需要注意，publishProgress需要调用不止一次，因此不可能每次都通过反射来创建DiffUtil的类对象(创建一次就够了)，因此，我们需要将上面的函数整理为以下格式：服务端的java代码层由于publishProgress传递的是整型数据，我们可以自定义一些整型常量来映射出对应的任务状态。还可以在该DiffUtil定义一个内部接口，这样其他类实现了该接口，就可以接收到底层返回的进度。结论到此为止，整个增量更新的服务端是实现就结束了，总结一下：我们首先在java中定义了一个本地native方法，通过javac和javap命令生成了对应的h头文件；然后改写bsdiff.cpp文件，实现刚才生成的头文件中的函数，并针对windows服务器改写bsdiff.cpp的函数内部的细节；最后进行将生成的dll文件放到了tomcat服务器中，利用System.loadLibrary函数加载dll文件，如果缺少依赖dll的话，就添加对应的dll文件；最后为了实现进度的显示，我们又定义了publishProgress方法，并在底层实现了该函数，在java端的DiffUtil类中定义了一个接口，让其他实现该接口的类可以接收到底层发布的进度。","categories":[{"name":"Android","slug":"Android","permalink":"http://www.vibrancy.cn/categories/Android/"}],"tags":[{"name":"增量更新","slug":"增量更新","permalink":"http://www.vibrancy.cn/tags/增量更新/"},{"name":"android","slug":"android","permalink":"http://www.vibrancy.cn/tags/android/"}]},{"title":"到底什么时候该使用MQ","slug":"when-to-use-MQ ","date":"2017-04-29T22:23:39.000Z","updated":"2017-05-15T11:56:10.616Z","comments":true,"path":"repository/when-to-use-MQ .html","link":"","permalink":"http://www.vibrancy.cn/repository/when-to-use-MQ .html","excerpt":"","text":"MQ的用途消息总线（Message Queue），后文称MQ，是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了MQ之后，消息发送上游只需要依赖MQ，逻辑上和物理上都不用依赖其他服务。不使用MQ的情况MQ作为互联网分层架构中的解耦利器，那为什么不是所有通讯都使用MQ呢？因为，调用与被调用的关系，是无法被MQ取代的。调用方实时依赖执行结果的业务场景，请使用调用，而不是MQ。MQ的缺陷系统更复杂，多了一个MQ组件；消息传递路径更长，延时增加；消息可靠性和重复性互为矛盾，消息不丢不重难以同时保证；上游无法知道下游的执行结果，这一点是很致命的。什么时候使用MQ场景一：数据驱动的任务依赖什么是任务依赖互联网公司经常在凌晨进行一些数据统计任务，这些任务之间有一定的依赖关系，比如：task3需要使用task2的输出作为输入；task2需要使用task1的输出作为输入；这样的话，tast1,task2,task3之间就有任务依赖关系，必须task1先执行，再task2执行，载task3执行。使用cron人工排执行时间表task1，0:00执行，经验执行时间为50分钟task2，1:00执行（为task1预留10分钟buffer），经验执行时间也是50分钟task3，2:00执行（为task2预留10分钟buffer）使用cron的缺点如果有一个任务执行时间超过了预留buffer的时间，将会得到错误的结果，因为后置任务不清楚前置任务是否执行成功，此时要手动重跑任务，还有可能要调整排班表。总任务的执行时间很长，总是要预留很多buffer，如果前置任务提前完成，后置任务不会提前开始。如果一个任务被多个任务依赖，这个任务将会称为关键路径，排班表很难体现依赖关系，容易出错。如果有一个任务的执行时间要调整，将会有多个任务的执行时间要调整采用MQ解耦方案task1准时开始，结束后发一个“task1 done”的消息task2订阅“task1 done”的消息，收到消息后第一时间启动执行，结束后发一个“task2done”的消息。task3同理采用MQ的优点不需要预留buffer，上游任务执行完，下游任务总会在第一时间被执行。依赖多个任务，被多个任务依赖都很好处理，只需要订阅相关消息即可有任务执行时间变化，下游任务都不需要调整执行时间。MQ使用注意MQ只用来传递上游任务执行完成的消息，并不用于传递真正的输入输出数据。典型场景二：上游不关心执行结果58同城的很多下游需要关注“用户发布帖子”这个事件比如招聘用户发布帖子后，招聘业务要奖励58豆，房产用户发布帖子后，房产业务要送2个置顶，二手用户发布帖子后，二手业务要修改用户统计数据。采用调用关系解决帖子发布服务执行完成之后，调用下游招聘业务、房产业务、二手业务，来完成消息的通知，但事实上，这个通知是否正常正确的执行，帖子发布服务根本不关注。采用调用的缺陷帖子发布流程的执行时间增加了下游服务宕机，可能导致帖子发布服务受影响，上下游逻辑+物理依赖严重。每当增加一个需要知道“帖子发布成功”信息的下游，修改代码的是帖子发布服务，这一点是最恶心的，属于架构设计中典型的依赖倒转，谁用过谁痛谁知道。采用MQ解耦方案帖子发布成功后，向MQ发一个消息哪个下游关注“帖子发布成功”的消息，主动去MQ订阅采用MQ的优点上游执行时间短上下游逻辑+物理解耦，除了与MQ有物理连接，模块之间都不相互依赖新增一个下游消息关注方，上游不需要修改任何代码。典型场景三：上游关注执行结果，但执行时间很长微信支付跨公网调用微信的接口，执行时间会比较长，但调用方又非常关注执行结果，此时一般怎么玩呢？采用“回调网关+MQ”方案来解耦：调用方直接跨公网调用微信接口微信返回调用成功，此时并不代表返回成功微信执行完成后，回调统一网关网关将返回结果通知MQ请求方收到结果通知总结什么时候不使用MQ？上游实时关注执行结果什么时候使用MQ？数据驱动的任务依赖上游不关心多下游执行结果异步返回执行时间长","categories":[{"name":"架构师","slug":"架构师","permalink":"http://www.vibrancy.cn/categories/架构师/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.vibrancy.cn/tags/架构/"},{"name":"消息队列","slug":"消息队列","permalink":"http://www.vibrancy.cn/tags/消息队列/"}]},{"title":"Tomcat多实例单应用部署方案","slug":"Tomcat-multi-instance-single-application-deployment-plan","date":"2017-04-29T02:20:53.000Z","updated":"2017-05-15T11:56:10.704Z","comments":true,"path":"repository/Tomcat-multi-instance-single-application-deployment-plan.html","link":"","permalink":"http://www.vibrancy.cn/repository/Tomcat-multi-instance-single-application-deployment-plan.html","excerpt":"","text":"Tomcat部署的场景分析单实例单应用如果不要求周期性地维护tomcat版本，一般的做法是把打好的war包丢到webapps目录下，然后执行startup.sh脚本，并且可以在浏览器里访问就行了。单实例多应用是把多个应用程序的war包放在同一个tomcat的webapps目录，这样一来，关闭和启动tomcat会影响所有项目。多实例单应用各个tomcat都运行同一个应用程序，对应地需要修改不同的监听端口，这种方式通常会和apache httpd或者nginx整合使用，做一些负载均衡的处理。多实例多应用相当于第一种场景的复数形式，除了修改不同的监听端口，没有本质区别。Windows服务器下多实例单应用设置流程分离目录刚解压出来的tomcat目录结构bin：主要存放脚本文件，例如比较常用的windows和linux系统中启动和关闭脚本conf：主要存放配置文件，其中最重要的两个配置文件是server.xml和web.xmllib：主要存放tomcat运行所依赖的包logs：主要存放运行时产生的日志文件，例如catalina.{date}.log等temp：存放tomcat运行时产生的临时文件，例如开启了hibernate缓存的应用程序，会在该目录下生成一些文件webapps：部署web应用程序的默认目录work：主要存放由JSP文件生成的servlet（java文件以及最终编译生成的class文件）将解压出来的tomcat文件拆分出的目录结构如下所示：1234567891011121314151617181920F:/DevLibs/Tomcat├─applications│ ├─backend # 主要部署后端模块代码│ │ │ shutdown.bat│ │ │ startup.bat│ │ ├─conf│ │ ├─logs│ │ ├─temp│ │ ├─webapps │ │ └─work│ └─officals-website # 主要部署前端代码，如官方网站│ │ shutdown.bat│ │ startup.bat│ ├─conf│ ├─logs│ ├─temp│ ├─webapps│ └─work├─bin└─lib修改环境变量环境变量说明CATALINA_HOME：即指向Tomcat安装路径的系统变量CATALINA_BASE：即指向活跃配置路径的系统变量通过设置这两个变量，就可以将tomcat的安装目录和工作目录分离，从而实现tomcat多实例的部署。环境变量设置新建变量名：CATALINA_HOME，变量值：F:/DevLibs/Tomcat不需要增加CATALINA_BASE，该变量在脚本中动态设置。打开PATH，添加变量值：%CATALINA_HOME%\\lib;%CATALINA_HOME%\\bin修改server.xml修改官方网站（officals-website）web应用的server.xml配置（端口号8081）。将第22行的&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; 修改为 &lt;Server port=&quot;8015&quot; shutdown=&quot;SHUTDOWN&quot;&gt;将第69行的&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; 修改为 &lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot;将第91行的&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;修改为&lt;Connector port=&quot;8019&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;将第123行的&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;修改为&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;false&quot;&gt;修改后端（backend）web应用的server.xml配置（端口号8082）。将第22行的&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; 修改为 &lt;Server port=&quot;8025&quot; shutdown=&quot;SHUTDOWN&quot;&gt;将第69行的&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; 修改为 &lt;Connector port=&quot;8082&quot; protocol=&quot;HTTP/1.1&quot;将第91行的&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;修改为&lt;Connector port=&quot;8029&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;将第123行的&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;修改为&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;false&quot;&gt;修改启动和停止脚本将初始tomcat的bin目录下的startup.bat 和shutdown.bat 这两个脚本分别拷贝到backend 和 offical-website 目录下编辑startup.bat脚本，增加一行语句，用于设置CATALINA_BASE变量。（backend和offical-website需要同时修改）1234567891011121314setlocalrem Guess CATALINA_HOME if not definedset &quot;CURRENT_DIR=%cd%&quot;## 在这里将CATALINA_BASE 设置为脚本所在目录set &quot;CATALINA_BASE=%cd%&quot; if not &quot;%CATALINA_HOME%&quot; == &quot;&quot; goto gotHomeset &quot;CATALINA_HOME=%CURRENT_DIR%&quot;if exist &quot;%CATALINA_HOME%\\bin\\catalina.bat&quot; goto okHomecd ..set &quot;CATALINA_HOME=%cd%&quot;cd &quot;%CURRENT_DIR%&quot;:gotHome编辑shutdown.bat脚本，增加一行语句，用于设置CATALINA_BASE变量。（backend和offical-website需要同时修改）12345678910111213setlocalrem Guess CATALINA_HOME if not definedset &quot;CURRENT_DIR=%cd%&quot;## 在这里将CATALINA_BASE 设置为脚本所在目录set &quot;CATALINA_BASE=%cd%&quot;if not &quot;%CATALINA_HOME%&quot; == &quot;&quot; goto gotHomeset &quot;CATALINA_HOME=%CURRENT_DIR%&quot;if exist &quot;%CATALINA_HOME%\\bin\\catalina.bat&quot; goto okHomecd ..set &quot;CATALINA_HOME=%cd%&quot;cd &quot;%CURRENT_DIR%&quot;:gotHome启动tomcats分别在backend和officals-website目录，用Dos执行startup.bat脚本。在浏览器输入loalhost:8081和loalhost:8082就可以访问tomcat管理页面了。参考文章Tomcat多实例单应用部署方案一个tomcat部署多个应用实例总结","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.vibrancy.cn/categories/Tomcat/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://www.vibrancy.cn/tags/tomcat/"}]}]}